{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Kh5QDL-p7Ar7"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import math\n",
        "from collections import Counter, defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loading dataset\n",
        "with open('/content/train.txt') as f:\n",
        "  train_data = f.read()"
      ],
      "metadata": {
        "id": "VJhlSBt97KN6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data"
      ],
      "metadata": {
        "id": "017P0CI57Oe6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = [re.sub(r'[^a-zA-Z]+', ' ', line).lower() for line in train_data.split('\\n') if len(line) > 0]\n",
        "\n",
        "# Add start and end tokens, and split into words\n",
        "train_list = [['$start'] + line.split() + ['$end'] for line in train_data]\n",
        "\n",
        "# Create unigram list\n",
        "train_unigram = [word for sentence in train_list for word in sentence]\n"
      ],
      "metadata": {
        "id": "V8eDR5Pr7ckq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unknown word handling train\n",
        "#replace words that appear less than 5 times with $unk\n",
        "count_unigrams = Counter(train_unigram)\n",
        "for i in range(len(train_unigram)):\n",
        "  if count_unigrams[train_unigram[i]]<=5:\n",
        "    train_unigram[i] = '$unk'"
      ],
      "metadata": {
        "id": "2Gf8h0nY7lIA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_bigram = [train_unigram[i] + '_' + train_unigram[i+1] for i in range(len(train_unigram)-1)]\n",
        "train_bigram = list(filter(lambda x: x!='$end_$start', train_bigram))"
      ],
      "metadata": {
        "id": "sXnKQBmfHHST"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unigram and bigram counts from train set\n",
        "count_unigrams = Counter(train_unigram)\n",
        "count_unigrams = defaultdict(lambda: 0, count_unigrams)\n",
        "count_bigrams = Counter(train_bigram)\n",
        "count_bigrams = defaultdict(lambda: 0, count_bigrams)"
      ],
      "metadata": {
        "id": "i2tFvsD-HLJB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Vocabulary size\n",
        "V = len(count_unigrams.keys())\n",
        "print(\"The vocabulary size \",V)\n",
        "print(\"The length of train_unigrams \",len(train_unigram))\n",
        "print(\"The length of train_bigrams \",len(train_bigram))\n",
        "count_unigrams['$unk']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gzdhz1-99Ej",
        "outputId": "1643dc0e-2414-4fb7-88b2-9a16bcf0052e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The vocabulary size  1262\n",
            "The length of train_unigrams  80376\n",
            "The length of train_bigrams  79864\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7814"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#unsmoothed probabilities\n",
        "unsmoothed_prob_unigrams = dict(map(lambda x: (x[0], x[1]/len(train_unigram)), count_unigrams.items()))\n",
        "unsmoothed_prob_bigrams = dict(map(lambda x: (x[0], x[1]/count_unigrams[x[0].split(\"_\")[0]]), count_bigrams.items()))"
      ],
      "metadata": {
        "id": "fjbf_yW0-azM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unsmoothed_prob_unigrams"
      ],
      "metadata": {
        "id": "H04M4kGd-gOq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unsmoothed_prob_bigrams"
      ],
      "metadata": {
        "id": "gUcNahQJAptu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def smoothed_uni_probability(word, k=1):\n",
        "    # Count of the word + smoothing factor k\n",
        "    cw = count_unigrams.get(word, 0) + k\n",
        "    # Total number of unigrams in the corpus + smoothing for vocabulary size\n",
        "    c = len(train_unigram) + k * V\n",
        "    # Return smoothed probability\n",
        "    return cw / c\n",
        "\n",
        "# Function to calculate perplexity for unigrams\n",
        "def perplexity_unigrams(x, k=1):\n",
        "    p = 0\n",
        "    n = len(x)  # Total number of unigrams in the input x\n",
        "\n",
        "    for word in x:\n",
        "        prob = smoothed_uni_probability(word, k)\n",
        "        if prob > 0:\n",
        "            p += np.log2(prob)\n",
        "\n",
        "    p = p / n\n",
        "    pp = math.pow(2, -p)\n",
        "    return pp"
      ],
      "metadata": {
        "id": "b5pX5Z43VgN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate smoothed probability for bigrams\n",
        "def smoothed_bi_probability(bigram, k=1):\n",
        "    # Count of the bigram + smoothing factor k\n",
        "    cw = count_bigrams.get(bigram, 0) + k\n",
        "    # Get the first word of the bigram\n",
        "    first_word = bigram.split(\"_\")[0]\n",
        "    # Count of the first word + smoothing for vocabulary size\n",
        "    c = count_unigrams.get(first_word, 0) + k * V\n",
        "    # Return smoothed probability\n",
        "    return cw / c\n",
        "\n",
        "# Function to calculate perplexity for bigrams\n",
        "def perplexity_bigrams(x, k=1):\n",
        "    p = 0\n",
        "    n = len(x)  # Total number of bigrams in the input x\n",
        "\n",
        "    for bigram in x:\n",
        "        prob = smoothed_bi_probability(bigram, k)\n",
        "        if prob > 0:\n",
        "            p += np.log2(prob)\n",
        "\n",
        "    p = p / n\n",
        "    pp = math.pow(2, -p)\n",
        "    return pp"
      ],
      "metadata": {
        "id": "fRY2exxgutkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(smoothed_uni_probability('we', k=1))\n",
        "print(smoothed_bi_probability('we',  k=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfJ6-cUOV4qR",
        "outputId": "9389766b-14b4-424f-9835-28fb531a6eaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.013712743775297437\n",
            "0.00044033465433729633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(perplexity_unigrams(train_unigram, k=1))\n",
        "print(perplexity_bigrams(train_bigram, k=1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaLDSQ6Iljr7",
        "outputId": "b12f100e-35fa-42d1-8124-e7c11c15005f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "209.16740676392953\n",
            "148.26608661608694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/val.txt') as f:\n",
        "  val_data = f.read()"
      ],
      "metadata": {
        "id": "2e9IvWRRxZPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = [re.sub(r'[^a-zA-Z]+', ' ', line).lower() for line in val_data.split('\\n') if len(line) > 0]\n",
        "\n",
        "# Add start and end tokens, and split into words\n",
        "val_list = [['$start'] + line.split() + ['$end'] for line in val_data]\n",
        "\n",
        "# Create unigram list\n",
        "val_unigram = [word for sentence in val_list for word in sentence]"
      ],
      "metadata": {
        "id": "rJU03vmxzzJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unknown word handling in val\n",
        "for i in range(len(val_unigram)):\n",
        "  if val_unigram[i] not in train_unigram:\n",
        "    val_unigram[i] = '$unk'\n",
        "\n",
        "val_bigram = [val_unigram[i] + '_' + val_unigram[i+1] for i in range(len(val_unigram)-1)]\n",
        "val_bigram = list(filter(lambda x: x!='$end_$start', val_bigram))"
      ],
      "metadata": {
        "id": "PLDdR_roz4xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pp_unigram_val = []\n",
        "pp_bigram_val = []\n",
        "\n",
        "# Validation set perplexities\n",
        "for k in [1, 0.5, 0.8]:\n",
        "    unigram_pp = perplexity_unigrams(val_unigram, k=k)\n",
        "    bigram_pp = perplexity_bigrams(val_bigram, k=k)\n",
        "\n",
        "    # Append results\n",
        "    pp_unigram_val.append(unigram_pp)\n",
        "    pp_bigram_val.append(bigram_pp)\n",
        "\n",
        "    # Print the results\n",
        "    print(f\"The Perplexity of Unigram-Validation for k={k}: {unigram_pp}\")\n",
        "    print(f\"The Perplexity of Bigram-Validation for k={k}: {bigram_pp}\")"
      ],
      "metadata": {
        "id": "vCYqMRyz0AKr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "687184ef-e9a6-4fd0-a844-745b74f45c6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Perplexity of Unigram-Validation for k=1: 205.56688506739232\n",
            "The Perplexity of Bigram-Validation for k=1: 177.64155153350805\n",
            "The Perplexity of Unigram-Validation for k=0.5: 205.4374918102955\n",
            "The Perplexity of Bigram-Validation for k=0.5: 141.2661179880533\n",
            "The Perplexity of Unigram-Validation for k=0.8: 205.51184093893193\n",
            "The Perplexity of Bigram-Validation for k=0.8: 164.38273828454047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pp_unigram_train = []\n",
        "pp_bigram_train = []\n",
        "\n",
        "# Train set perplexities\n",
        "for k in [1, 0.5, 0.8]:\n",
        "    # Compute perplexities\n",
        "    unigram_pp = perplexity_unigrams(train_unigram, k=k)\n",
        "    bigram_pp = perplexity_bigrams(train_bigram, k=k)\n",
        "\n",
        "    # Append results to lists\n",
        "    pp_unigram_train.append(unigram_pp)\n",
        "    pp_bigram_train.append(bigram_pp)\n",
        "\n",
        "    # Print the perplexity for the current smoothing factor\n",
        "    print(f\"Perplexity of Unigram-Train for k={k}: {unigram_pp}\")\n",
        "    print(f\"Perplexity of Bigram-Train for k={k}: {bigram_pp}\")"
      ],
      "metadata": {
        "id": "MHH1Vw6d5J3S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77bcfa16-17a9-4b57-ba71-ea49d521ce48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity of Unigram-Train for k=1: 209.16740676392953\n",
            "Perplexity of Bigram-Train for k=1: 148.26608661608694\n",
            "Perplexity of Unigram-Train for k=0.5: 209.11499725767476\n",
            "Perplexity of Bigram-Train for k=0.5: 108.4268781205447\n",
            "Perplexity of Unigram-Train for k=0.8: 209.14259196505088\n",
            "Perplexity of Bigram-Train for k=0.8: 133.81461000623858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pp_unigram_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpZMdgUL5DZQ",
        "outputId": "96e6b8b8-7885-4aec-872b-65f5570c9187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[209.16740676392953, 209.11499725767476, 209.14259196505088]"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pp_unigram_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQzZTf6G6rFD",
        "outputId": "f4ab15b9-0929-4f28-8136-d89b88effed7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[205.56688506739232, 205.4374918102955, 205.51184093893193]"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pp_bigram_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyLqkzxYslCx",
        "outputId": "5dba4d9f-08cf-4f21-dbd8-10ac84f9a392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[148.26608661608694, 108.4268781205447, 133.81461000623858]"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pp_bigram_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYoJfT1k6xTc",
        "outputId": "1417bdd4-857c-4cc3-a292-1b0d9789e6db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[177.64155153350805, 141.2661179880533, 164.38273828454047]"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    }
  ]
}